\documentclass[notes]{beamer}
\usepackage{hyperref}
\usepackage[T1]{fontenc}
\UseRawInputEncoding

\usepackage{pgfpages}
\setbeameroption{show notes on second screen=right}
%\usepackage[backend=biber]{biblatex} 
\usepackage[square,comma,numbers]{natbib}

% other packages
\usepackage{latexsym,amsmath,xcolor,multicol,booktabs,calligra}
\usepackage{graphicx,listings,stackengine,subfig}
\usepackage{multirow}
\renewcommand{\footnotesize}{\tiny}

\title{Multiclass Classification Of Leptons In Proton-Proton Collisions At \textsurd s=13 TeV Using Machine Learning}
\author{Kristoffer Langstad}
\institute{University of Oslo, Department of Physics}
\date{\today}


\begin{document}
	\begin{frame}[t]{Thesis Presentation}
		\titlepage
	\end{frame}


	\begin{frame}[t]{Outline}
		\begin{enumerate}
			\item Introduction
				\begin{enumerate}[(i)]
					\item Particle physics model
					\item Machine Learning
				\end{enumerate}
			\item Multiclass Classification
			\item Results
			\item Summary, Conclusion and Outlook
		\end{enumerate}
	\end{frame}



	\begin{frame}[t]{Standard Model}
		\begin{figure}[ht!]
			\centering
			\includegraphics[width=0.8\linewidth]{SM.png}
			\caption{The Standard Model contents, source \cite{SM}. \label{fig:SM}}
		\end{figure} 
	\end{frame}
	\note{
		SM explain with great precision. Fundamental particles in figure w/ charge, spin and mass.
		Does not explain graviton and non-zero mass of neutrino. Know from neutrino oscillations they change flavor and must have mass.
		
		Introduce Inverse seesaw mechanism w/ heavy neutrinos and right-handed neutrinos. Only left-handed neutrinos, LH and RH for other SM particles. LH means direction of spin and motion are opposite. ISS-> trilepton final state with a neutrino through p-p collisions and decay through W-boson and heavy pseudo-Dirac neutrino. Continue to next slide with model->
	}


	\begin{frame}[t]{Trilepton Final State}
		\begin{figure}[htbp!]
			\centering\includegraphics[width=0.8\linewidth]{ModelProcess.png}
			\caption{The Born diagram for the charged current Drell-Yan process of the proton-proton collision (on the left) producing a heavy pseudo-Dirac neutrino $N$ in the inverse seesaw mechanism model, leading to a trilepton plus missing transverse energy (a light neutrino) final state. Figure is taken from ref. \citet{inverseseesaw}. \label{fig:ModelProcessIntro}}
		\end{figure}
	\end{frame}
	\note{
		Figure of P-P collisions to trilepton final state and decays. Charges. At LHC and CERN, detected by ATLAS but neutrinos are not. Only MET since conservation of energy.
		
		Called charged current Drell-Yan process, same model we look at for neutrinos as by \citet{inverseseesaw}. Gives almost conserved lepton number and consider only electrons and muons. Amount of SS and OS events vertex 1 and 2 differ from normal seesaw. Allows LFV for vertex 1 and 2 for e and mu. Study two simulated neutrino signals, mass 150 GeV and 450 GeV, expect different LFV for different neutrino mass models.
		
		Not always trivial to identify particles. P-P collisions simulated, and measure properties like momentum, transverse momentum and coord-angles. Make new variables dPhi, dR and mll.
	}


	\begin{frame}[t]{Proton-Proton Collision Data}
		\begin{figure}[htb!]
			\hspace*{-0.6cm}
			\centering\includegraphics[width=0.8\linewidth]{dataFlow.png}
			\caption{The data flow for producing the proton-proton collision data and simulations. Credit: \citet{catmore2020atlas}. \label{fig:DataFlow}}
		\end{figure}
	\end{frame}
	\note{
		MC simulated backgrounds, simulated neutrinos and p-p data at 13 TeV from LHC 2018 - data flow left side - not interesting. MC and signals - right side - ML. 
		
		Signal sim - train ML - after Generation - truth - sim of event interactions quark/gluons + subsequent decays. Next steps - sim particle interactions w/detectors - conv sim to "real" raw data as hist - reduce amount of data. MC - best represent all prod-mech with trilepton+MET. MC + signals - classif after Analysis.
	}


	\begin{frame}[t]{Machine Learning Process}
		\begin{block}{What we want to do:}
			Use machine learning to identify lepton vertices in simulated backgrounds and signals.
		\end{block}
		\begin{block}{How to do it:}
			\begin{enumerate}[I]
				\item Use supervised learning and multiclass classification.
				\item Train and optimize machine learning algorithms
				\item Evaluate which model that best predicts the vertices.
				\item Predict lepton vertices for simulated backgrounds and signals.
			\end{enumerate}
		\end{block}
		\begin{block}{End goal:}
			\begin{enumerate}[I]
				\item Look for lepton flavor violation between the classified leptons 1 and 2.
				\item Compare with a more standard analysis by \citet{inverseseesaw}.
			\end{enumerate}
		\end{block}
	\end{frame}
	\note{
		Machine learning to train to identify the particles vertices, pattern recognition in particle properties. Truth simulated data, know the origins and what particles have been produced. Train various ML algorithms, use best performing model to predict simulated backgrounds and signals. Six different lepton vertex permutations. Multiclass classification case with six classes, not been studied much previously in particle physics. 
		
		Need good and fast algorithms for classification, lot of data to work with. Need preprocessing of data before classification. Train models on training set. Many hyperparameters to optimize on validation set. Evaluation metrics for performance evaluation for validation and test set. Export best model, skips training the models each time.
		
		Signal region cuts to study LFV for lepton 1 and 2. Compare with a more standard analysis by \citet{inverseseesaw}.
	}


	\begin{frame}[t]{Preprocessing of Data}
		\begin{enumerate}[(i)]
			\item Feature correlations
			\item Resampling
			\item Splitting into data sets
			\item Scaling
		\end{enumerate}
	\end{frame}
	\note{
		Check correlations - strong correlations=strong linear dependence=remove one feature=should give better results. Information gain - want higher values=features have more information regarding the classes.
		
		Imbalanced data=more data for some classes (bias)=bad predictions of minority classes - resampling techniques to balance classes (number of events).
		
		Split data - training, validation, test - training=train models - validation=tune model hyperparameters and check models - test=check final performance of (tuned) models.
		
		Scale - avoid weighted favoring of some classes - only for features - standardization=0 mean, 1 std.dev.
		
		Tune with a randomized search method with cross-validation for different hyperparameters depending on classification type and algorithm. 
	}


	\begin{frame}[t]{Bias-Variance Tradeoff}
		\begin{figure}[htbp!]
			\centering\includegraphics[width=0.8\linewidth]{bias-variance.png}
			\caption{Illustration of the quality of a model from how well it does on data not seen during training with variance and bias regions. Source by \citet{mehta2019high}. \label{fig:BiasVar}}
		\end{figure}
	\end{frame}
	\note{
		Supervised learning problem - balance between variance and bias - best compromise=best model for model complexity/number of data points. High bias=underfitting - high variance=overfitting. Overfitting more normal today. Figure - optimal at test minimum. Quality of model - on data not seen during training.
	}


	\begin{frame}[t]{Classification Algorithms}
		Types of classification algorithms used:
		\begin{enumerate}[(i)]
			\item Logistic regression
			\item Multi-layer perceptron
			\item Trees
			\item Boosters
			\item Multiclassifiers
		\end{enumerate}
	\end{frame}
	\note{
		Binary classifiers to multiclass: LR - linear regression with a logistic function to predict. MLP - neural network - input, hidden, output layers - weights, biases, non-linear activation func to output - hyperparameters, regularization control overfitting. DTC - simpler, single tree model with features - criterion for value splits - control hyperparm for overfit. RF - ensemble of trees - increase accuracy, decease variance. Boost - iteration weights - sequential models built - better classifier. AdaBoost - adaptive boost - weights adapt each iteration - majority vote -> better classifier. GradientBoost - tree boost approx Ada - weighted gradient in loss func - HistGradient larger data sets - less time, higher accuracy - bins. XGB - opt hist dist grad boost alg - accurate fast parallel - scalable -  dist of features - complex w/hyperparameters. LGBM - distributed gradient boost - faster, memory efficient, accurate - large data sets - information gain - drop feat threshold.
		
		Multiclass: Multiclass to binary cases techniques.
	}


	\begin{frame}[t]{Classification Results}
		\begin{table}[htbp!]
			\centering
			%\hspace{-1cm}
			\begin{tabular}{ |c|c|c|c|c| }
				\hline \rule{0pt}{13pt}
				\multirow{2}{*}{Model} & \multicolumn{4}{c|}{Signal models} \\
				\cline{2-5} \rule{0pt}{13pt}
				 & \multicolumn{2}{c|}{150 GeV} & \multicolumn{2}{c|}{450 GeV} \\
				\cline{2-5} \rule{0pt}{13pt}
				 & Score & Score\_train & Score & Score\_train \\
				\hline \rule{0pt}{13pt}
				AdaBoost & 0.8519 & 1.0000 & 0.9385 & 1.0000 \\
				\hline \rule{0pt}{13pt}
				OvO & 0.7788 & 0.9299 & 0.9088 & 0.9319 \\
				\hline \rule{0pt}{13pt}
				MLP & 0.8227 & 0.9492 & 0.9350 & 0.9606 \\
				\hline \rule{0pt}{13pt}
				HGBC & 0.7863 & 0.8999 & 0.9280 & 0.9571 \\
				\hline \rule{0pt}{13pt}
				XGBoost & 0.8631 & 0.9998 & 0.9509 & 0.9999 \\
				\hline \rule{0pt}{13pt}
				LGBM & \textbf{0.8779} & 0.9999 & \textbf{0.9541} & 0.9999\\
				\hline
			\end{tabular}	
			\caption{Accuracy scores of the highest performing classification models trained on the 150 GeV and 450 GeV validation and training sets.}
			\label{tab:Validation}
		\end{table}
	\end{frame}
	\note{
		Highest scoring - both signals - validation and training scores. Tendency to overfit - 450 scores closer. XGB and LGBM best - LGBM better and faster - LGBM chosen.
	}


	\begin{frame}[t]{Light Gradient Boosting Machine}
		\begin{figure}[h]
			\centering
			\subfloat{\includegraphics[width=0.5\textwidth]{Test_plots/Conf_mat_150.png}}
			\subfloat{\includegraphics[width=0.5\textwidth]{Test_plots/Conf_mat_450.png}}
			\caption{Light Gradient Boosting Mechanism (LGBM) confusion matrix on the test set for both signals.}
		\end{figure}
	\end{frame}
	\note{
		LGBM on test data - no tuning - more metrics. Confusion matrices - diagonal between 0.8-1.0 - good predictions. 450 GeV more accurate - 132, 231, 312, 321 better accuracy.
	}


	\begin{frame}[t]{Scores}
		\begin{table}[htb!]
			%\hspace{-0.8cm}
			\centering
			\begin{tabular}{ |c|c|c|c|c| }
				\hline \rule{0pt}{13pt}
				Signal [GeV] & Score & Score\_train & CKS & LogLoss  \\
				\hline \rule{0pt}{13pt}
				150 & 0.8793 & 0.9999 & 0.8551 & 0.3335 \\
				\hline \rule{0pt}{13pt}
				450 & 0.9570 & 0.9999 & 0.9484 & 0.1120 \\
				\hline
			\end{tabular}	         
			\caption{Accuracy score of both the test and training sets, Cohen Kappe score and logloss for both the 150 and 450 GeV signal models.}
			\label{tab:Test}
		\end{table}
		\begin{table}[htb!]
			%\hspace{-0.8cm}
			\centering
			\begin{tabular}{ |c|c|c|c| }
				\hline \rule{0pt}{13pt}
				\multirow{2}{*}{Signal [GeV]} & \multicolumn{2}{c|}{ROC} & \multicolumn{1}{c|}{Precision-Recall}\\
				\cline{2-4} \rule{0pt}{13pt}
				 & Micro AUC & Macro AUC & Micro AUC  \\
				\hline \rule{0pt}{13pt}
				150 & 0.99 & 0.99 & 0.949 \\
				\hline \rule{0pt}{13pt}
				450 & 1.0 & 1.0 & 0.994  \\
				\hline
			\end{tabular}	         
			\caption{Micro and macro area under the curve (AUC) scores for both ROC and precision-recall curves.}
			\label{tab:AUC}
		\end{table}
	\end{frame}
	\note{
		Table 1: Accuracy scores, CKS and log loss (error) of LGBM - validation and test similar accuracy - good for different data - NB: same original data set. 450 GeV still better - high acc - low log loss.
		
		Table 2: Micro and macro AUC for ROC and precision-recall - show overall performance - AUC over 0.8=good model - both values over 0.9. LGBM shows great promise on predicting the vertices on these test set.
	}


	\begin{frame}[t]{Classify Simulated Data}
		What to classify with the LGBM:
		\begin{enumerate}[(i)]
			\item Simulated background production-mechanisms with trilepton final states plus MET.
			\item Two reconstructed neutrino signals, with neutrino masses of 150 and 450 GeV.
		\end{enumerate}
	
		\begin{itemize}
			\item Use classified vertex permutations to define new signal regions with opposite sign and same flavor or opposite flavor for lepton 1 and 2.
			\item Compare signal regions with benchmark analysis.
		\end{itemize}
		
	\end{frame}
	\note{
		...
	}


	\begin{frame}[t]{title}
		content...
	\end{frame}
	\note{
		...
	}


	\begin{frame}[t]{Summary and Outlook}
		content...
	\end{frame}
	\note{
		...
	}

	
	\begin{frame}[t]{Predicted Signal Vertices}
		\begin{figure}[htbp!]
			\centering\includegraphics[width=0.6\linewidth]{Signal_table.png}
			\caption{Number of events for each vertex of the two signals and the fraction for each vertex. Left: the truth data we used to train our classifiers on. Middle: The truth vertices for the reconstructed signals we predict. Right: The classified vertices of the reconstructed signals. \label{fig:NeutrinoClass}}
		\end{figure}
	\end{frame}
	\note{
		Extra: Notice classified vertices vs truth of reconstructed vertices.
		...
	}
	
%--------------
	\begin{frame}[t]{References}
		\bibliographystyle{unsrtnat} %plain, unsrt, abbrv
		\bibliography{Refs}
	\end{frame}

\end{document}